{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ead9ad26-645a-67ab-dd70-b1c11e857df0"
   },
   "source": [
    "Keras + CV\n",
    "\n",
    "Thanks @anokas for the starter code at https://www.kaggle.com/anokas/planet-understanding-the-amazon-from-space/simple-keras-starter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b7d410c7-f998-dff8-7a24-2ac74cb5e0f5",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ef20ca3-ccf0-3756-43e1-6f4eef4e4fd7"
   },
   "source": [
    "Pre-processing the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ee3230e-2334-a865-76fd-4e8efcf0dade",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 20000/20000 [07:36<00:00, 43.84it/s]  0%|                                                | 0/20000 [00:20<?, ?it/s]\n",
      "100%|████████████████████████████████████| 40669/40669 [11:20<00:00, 59.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32, 3)\n",
      "(20000, 17)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('../data/train_csv/train.csv')\n",
    "df_test = pd.read_csv('../data/sample_submission_csv/sample_submission.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:20000], miniters=1000):\n",
    "    img = cv2.imread('../data/train-jpg/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "#     print(img)\n",
    "    x_train.append(cv2.resize(img, (32, 32)))\n",
    "    y_train.append(targets)\n",
    "\n",
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    img = cv2.imread('../data/test-jpg/test-jpg/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (32, 32)))\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32) / 255.\n",
    "x_test  = np.array(x_test, np.float32) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.25098041,  0.27843139,  0.23529412],\n",
       "        [ 0.20392157,  0.25490198,  0.20392157],\n",
       "        [ 0.25490198,  0.30980393,  0.25490198],\n",
       "        ..., \n",
       "        [ 0.22352941,  0.24705882,  0.2       ],\n",
       "        [ 0.27843139,  0.35294119,  0.29019609],\n",
       "        [ 0.25882354,  0.28235295,  0.24705882]],\n",
       "\n",
       "       [[ 0.25882354,  0.30980393,  0.27058825],\n",
       "        [ 0.25882354,  0.29019609,  0.24313726],\n",
       "        [ 0.24313726,  0.29019609,  0.24705882],\n",
       "        ..., \n",
       "        [ 0.24705882,  0.25490198,  0.21960784],\n",
       "        [ 0.26274511,  0.30588236,  0.27450982],\n",
       "        [ 0.25490198,  0.34509805,  0.27843139]],\n",
       "\n",
       "       [[ 0.25098041,  0.29411766,  0.25098041],\n",
       "        [ 0.27058825,  0.32156864,  0.27450982],\n",
       "        [ 0.25490198,  0.29803923,  0.25882354],\n",
       "        ..., \n",
       "        [ 0.23137255,  0.27058825,  0.22352941],\n",
       "        [ 0.25490198,  0.26666668,  0.23529412],\n",
       "        [ 0.25882354,  0.32156864,  0.26666668]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.32156864,  0.43529412,  0.41176471],\n",
       "        [ 0.31764707,  0.44313726,  0.41568628],\n",
       "        [ 0.30980393,  0.39607844,  0.36862746],\n",
       "        ..., \n",
       "        [ 0.25098041,  0.27450982,  0.22745098],\n",
       "        [ 0.24313726,  0.28627452,  0.22745098],\n",
       "        [ 0.25490198,  0.27843139,  0.22352941]],\n",
       "\n",
       "       [[ 0.32549021,  0.43921569,  0.39607844],\n",
       "        [ 0.31764707,  0.41960785,  0.39607844],\n",
       "        [ 0.32156864,  0.41960785,  0.37254903],\n",
       "        ..., \n",
       "        [ 0.23529412,  0.23137255,  0.2       ],\n",
       "        [ 0.24705882,  0.27450982,  0.24313726],\n",
       "        [ 0.21960784,  0.25882354,  0.21568628]],\n",
       "\n",
       "       [[ 0.32156864,  0.42745098,  0.39607844],\n",
       "        [ 0.33725491,  0.42745098,  0.39215687],\n",
       "        [ 0.3137255 ,  0.41960785,  0.39215687],\n",
       "        ..., \n",
       "        [ 0.24705882,  0.23529412,  0.2       ],\n",
       "        [ 0.26274511,  0.30588236,  0.24705882],\n",
       "        [ 0.25098041,  0.29411766,  0.26666668]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c405653c-ad09-7f27-e6c3-46f69fa68e32"
   },
   "source": [
    "Transpose the data if use Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "98204397-e87c-7530-9ca9-78335aba9b92",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.transpose((0, 3, 1, 2))\n",
    "x_test = x_test.transpose((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.25882354,  0.28235295,  0.24313726],\n",
       "        [ 0.27450982,  0.31764707,  0.27843139],\n",
       "        [ 0.27058825,  0.30588236,  0.25882354],\n",
       "        ..., \n",
       "        [ 0.28235295,  0.32156864,  0.28627452],\n",
       "        [ 0.29411766,  0.33333334,  0.31764707],\n",
       "        [ 0.3019608 ,  0.33725491,  0.30980393]],\n",
       "\n",
       "       [[ 0.26666668,  0.29803923,  0.25490198],\n",
       "        [ 0.27450982,  0.30980393,  0.27843139],\n",
       "        [ 0.25490198,  0.27450982,  0.23529412],\n",
       "        ..., \n",
       "        [ 0.28627452,  0.3137255 ,  0.28627452],\n",
       "        [ 0.28235295,  0.31764707,  0.27450982],\n",
       "        [ 0.29019609,  0.32549021,  0.29411766]],\n",
       "\n",
       "       [[ 0.27058825,  0.3019608 ,  0.28235295],\n",
       "        [ 0.26274511,  0.3019608 ,  0.27058825],\n",
       "        [ 0.27843139,  0.31764707,  0.28235295],\n",
       "        ..., \n",
       "        [ 0.26274511,  0.29411766,  0.25490198],\n",
       "        [ 0.27843139,  0.29019609,  0.24705882],\n",
       "        [ 0.27843139,  0.29019609,  0.25490198]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.27058825,  0.29411766,  0.26666668],\n",
       "        [ 0.27450982,  0.31764707,  0.28235295],\n",
       "        [ 0.27058825,  0.29411766,  0.25882354],\n",
       "        ..., \n",
       "        [ 0.26666668,  0.28627452,  0.25098041],\n",
       "        [ 0.29803923,  0.33333334,  0.30588236],\n",
       "        [ 0.28627452,  0.31764707,  0.28627452]],\n",
       "\n",
       "       [[ 0.27450982,  0.30980393,  0.27450982],\n",
       "        [ 0.28235295,  0.30588236,  0.27058825],\n",
       "        [ 0.27450982,  0.30980393,  0.25882354],\n",
       "        ..., \n",
       "        [ 0.29019609,  0.31764707,  0.29803923],\n",
       "        [ 0.29411766,  0.32549021,  0.29803923],\n",
       "        [ 0.28627452,  0.32549021,  0.28627452]],\n",
       "\n",
       "       [[ 0.27450982,  0.3019608 ,  0.27843139],\n",
       "        [ 0.27843139,  0.3137255 ,  0.28235295],\n",
       "        [ 0.25490198,  0.27843139,  0.23529412],\n",
       "        ..., \n",
       "        [ 0.28235295,  0.3137255 ,  0.27450982],\n",
       "        [ 0.27843139,  0.3019608 ,  0.26274511],\n",
       "        [ 0.28627452,  0.33333334,  0.29803923]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9150f6db-6b97-1fe3-42af-607d640df739"
   },
   "source": [
    "Create n-folds cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5b79bc1-fb26-a87b-f2ab-23c1b37a00c0",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 3\n",
      "Split train:  13333 13333\n",
      "Split valid:  6667 6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3...)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13333 samples, validate on 6667 samples\n",
      "Epoch 1/7\n",
      "22s - loss: 0.3280 - acc: 0.8761 - val_loss: 0.2525 - val_acc: 0.9047\n",
      "Epoch 2/7\n",
      "23s - loss: 0.2453 - acc: 0.9063 - val_loss: 0.2253 - val_acc: 0.9102\n",
      "Epoch 3/7\n",
      "23s - loss: 0.2271 - acc: 0.9126 - val_loss: 0.2112 - val_acc: 0.9174\n",
      "Epoch 4/7\n",
      "24s - loss: 0.2110 - acc: 0.9169 - val_loss: 0.1975 - val_acc: 0.9219\n",
      "Epoch 5/7\n",
      "24s - loss: 0.2021 - acc: 0.9212 - val_loss: 0.2086 - val_acc: 0.9208\n",
      "Epoch 6/7\n",
      "29s - loss: 0.1981 - acc: 0.9222 - val_loss: 0.1862 - val_acc: 0.9279\n",
      "Epoch 7/7\n",
      "53s - loss: 0.1913 - acc: 0.9247 - val_loss: 0.1840 - val_acc: 0.9285\n",
      "0.817821450644\n",
      "Start KFold number 2 from 3\n",
      "Split train:  13333 13333\n",
      "Split valid:  6667 6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3...)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13333 samples, validate on 6667 samples\n",
      "Epoch 1/7\n",
      "32s - loss: 0.3128 - acc: 0.8870 - val_loss: 0.2420 - val_acc: 0.9063\n",
      "Epoch 2/7\n",
      "36s - loss: 0.2426 - acc: 0.9079 - val_loss: 0.2351 - val_acc: 0.9091\n",
      "Epoch 3/7\n",
      "41s - loss: 0.2267 - acc: 0.9132 - val_loss: 0.2169 - val_acc: 0.9163\n",
      "Epoch 4/7\n",
      "47s - loss: 0.2177 - acc: 0.9156 - val_loss: 0.2176 - val_acc: 0.9148\n",
      "Epoch 5/7\n",
      "45s - loss: 0.2101 - acc: 0.9175 - val_loss: 0.2019 - val_acc: 0.9192\n",
      "Epoch 6/7\n",
      "36s - loss: 0.2052 - acc: 0.9196 - val_loss: 0.2009 - val_acc: 0.9225\n",
      "Epoch 7/7\n",
      "43s - loss: 0.1989 - acc: 0.9224 - val_loss: 0.1912 - val_acc: 0.9255\n",
      "0.810891837524\n",
      "Start KFold number 3 from 3\n",
      "Split train:  13334 13334\n",
      "Split valid:  6666 6666\n",
      "Train on 13334 samples, validate on 6666 samples\n",
      "Epoch 1/7\n"
     ]
    }
   ],
   "source": [
    "nfolds = 3\n",
    "\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "\n",
    "yfull_test = []\n",
    "yfull_train =[]\n",
    "\n",
    "kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        kfold_weights_path = os.path.join('', 'weights_kfold_' + str(num_fold) + '.h5')\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(32, 32, 3)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(48, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "        \n",
    "        model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=128,verbose=2, nb_epoch=7,callbacks=callbacks,)\n",
    "        \n",
    "        if os.path.isfile(kfold_weights_path):\n",
    "            model.load_weights(kfold_weights_path)\n",
    "        \n",
    "        p_valid = model.predict(X_valid, batch_size = 128, verbose=2)\n",
    "        print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n",
    "        \n",
    "        p_test = model.predict(x_train, batch_size = 128, verbose=2)\n",
    "        yfull_train.append(p_test)\n",
    "        \n",
    "        p_test = model.predict(x_test, batch_size = 128, verbose=2)\n",
    "        yfull_test.append(p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33dba992-7427-37bb-e233-d33b00c77c0b"
   },
   "source": [
    "Averaging the prediction from each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56d6d764-54a1-c68e-ba16-a44f46328aef",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.array(yfull_test[0])\n",
    "for i in range(1, nfolds):\n",
    "    result += np.array(yfull_test[i])\n",
    "result /= nfolds\n",
    "result = pd.DataFrame(result, columns = labels)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "237fd9e0-4ef4-2a9a-c62d-cf7ea5ecc329"
   },
   "source": [
    "Output prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e71169d-c19a-6e4c-eb26-e14722ccaae5",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.ix[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6b423b2-2432-7bd0-5f8e-ef2fe8d49bd0",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['tags'] = preds\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "57278b15-31ba-6800-523d-c6a63fc287f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('submission_keras.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 5,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
