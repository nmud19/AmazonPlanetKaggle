{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "558c6543-7398-38be-cb27-f039ea547cbb"
   },
   "source": [
    "Image Features\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "c571eb29-4e46-e89b-0057-d1d529f2df21",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import fbeta_score\n",
    "from PIL import Image, ImageStat\n",
    "from skimage import io\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, cv2\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "global count\n",
    "count = 0\n",
    "def get_features(path):\n",
    "    print (\"Here\")\n",
    "    try:\n",
    "        print( \"Trial\")\n",
    "        st = []\n",
    "        #pillow jpg\n",
    "        img = Image.open(path)\n",
    "        im_stats_ = ImageStat.Stat(img)\n",
    "        st += im_stats_.sum\n",
    "        st += im_stats_.mean\n",
    "        st += im_stats_.rms\n",
    "        st += im_stats_.var\n",
    "        st += im_stats_.stddev\n",
    "        img = np.array(img)[:,:,:3]\n",
    "        st += [scipy.stats.kurtosis(img[:,:,0].ravel())]\n",
    "        st += [scipy.stats.kurtosis(img[:,:,1].ravel())]\n",
    "        st += [scipy.stats.kurtosis(img[:,:,2].ravel())]\n",
    "        st += [scipy.stats.skew(img[:,:,0].ravel())]\n",
    "        st += [scipy.stats.skew(img[:,:,1].ravel())]\n",
    "        st += [scipy.stats.skew(img[:,:,2].ravel())]\n",
    "        #cv2 jpg\n",
    "        img = cv2.imread(path)\n",
    "        ## Generate no of rectangles\n",
    "        coloured_contours = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)[-2]\n",
    "        st += [coloured_contours]\n",
    "        #\n",
    "        bw = cv2.imread(path,0)\n",
    "        bnw_contours = cv2.findContours(bw,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)[-2]\n",
    "        st += [bnw_contours]\n",
    "        # get avg colour\n",
    "        avg_greyscale_colour = bw.mean()\n",
    "        avg_colour = img.mean()\n",
    "        st += [round(avg_greyscale_colour,6)]\n",
    "        st += [round(avg_colour,6)]\n",
    "        #\n",
    "        st += list(cv2.calcHist([bw],[0],None,[256],[0,256]).flatten()) #bw \n",
    "        st += list(cv2.calcHist([img],[0],None,[256],[0,256]).flatten()) #r\n",
    "        st += list(cv2.calcHist([img],[1],None,[256],[0,256]).flatten()) #g\n",
    "        st += list(cv2.calcHist([img],[2],None,[256],[0,256]).flatten()) #b\n",
    "        try:\n",
    "            #skimage tif\n",
    "            imgr = io.imread(path.replace('jpg','tif'))\n",
    "            tf = imgr[:, :, 3]\n",
    "            st += list(cv2.calcHist([tf],[0],None,[256],[0,65536]).flatten()) #near ifrared\n",
    "            ndvi = ((imgr[:, :, 3] - imgr[:, :, 0]) / (imgr[:, :, 3] + imgr[:, :, 0])) #water ~ -1.0, barren area ~ 0.0, shrub/grass ~ 0.2-0.4, forest ~ 1.0\n",
    "            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n",
    "            ndvi = ((imgr[:, :, 3] - imgr[:, :, 1]) / (imgr[:, :, 3] + imgr[:, :, 1]))\n",
    "            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n",
    "            ndvi = ((imgr[:, :, 3] - imgr[:, :, 2]) / (imgr[:, :, 3] + imgr[:, :, 2]))\n",
    "            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n",
    "        except:\n",
    "            st += [-1 for i in range(256)]\n",
    "            st += [-2 for i in range(60)]\n",
    "            print('err', path.replace('jpg','tif'))\n",
    "        m, s = cv2.meanStdDev(img) #mean and standard deviation\n",
    "        st += list(m)\n",
    "        st += list(s)\n",
    "        st += [cv2.Laplacian(bw, cv2.CV_64F).var()] \n",
    "        st += [cv2.Laplacian(img, cv2.CV_64F).var()]\n",
    "        st += [cv2.Sobel(bw,cv2.CV_64F,1,0,ksize=5).var()]\n",
    "        st += [cv2.Sobel(bw,cv2.CV_64F,0,1,ksize=5).var()]\n",
    "        st += [cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5).var()]\n",
    "        st += [cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5).var()]\n",
    "        st += [(bw<30).sum()]\n",
    "        st += [(bw>225).sum()]\n",
    "    except:\n",
    "        print(path)\n",
    "        print (\"Caught exception\")\n",
    "\n",
    "    return [path, st]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_img(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_features, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing for train\n"
     ]
    }
   ],
   "source": [
    "in_path = '../data/'\n",
    "train = pd.read_csv(\"D:\\\\Kaggle\\\\UnderstandingAmazonFromSpace\\\\data\\\\train_csv\\\\train.csv\")\n",
    "train['path'] = train['image_name'].map(lambda x: 'D:\\\\Kaggle\\\\UnderstandingAmazonFromSpace\\\\data\\\\train-jpg\\\\train-jpg\\\\' \n",
    "                                        + x + \n",
    "                                        '.jpg')\n",
    "y = train['tags'].str.get_dummies(sep=' ')\n",
    "print(\"doing for train\")\n",
    "xtrain = normalize_img(train['path'])\n",
    "print('train...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_jpg = glob.glob(in_path + 'test-jpg/test-jpg/*')\n",
    "test = pd.DataFrame([[p.split('/')[3].replace('.jpg',''),p] for p in test_jpg])\n",
    "test.columns = ['image_name','path']\n",
    "xtest = normalize_img(test['path'])\n",
    "print('test...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b375771-34eb-9cfc-0c19-2471c780bfa3"
   },
   "source": [
    "Model 1\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1cf42207-a2d3-6eff-324a-af4134836b88",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(n_estimators=200, max_depth=30, n_jobs=-1, random_state=1)\n",
    "etr.fit(xtrain, y); print('etr fit...')\n",
    "\n",
    "train_pred = etr.predict(xtrain)\n",
    "train_pred[train_pred > 0.20] = 1\n",
    "train_pred[train_pred < 1] = 0\n",
    "print(fbeta_score(y,train_pred,beta=2, average='samples'))\n",
    "\n",
    "pred1 = etr.predict(xtest); print('etr predict...')\n",
    "etr_test = pd.DataFrame(pred1, columns=y.columns)\n",
    "etr_test['image_name'] =  test[['image_name']]\n",
    "\n",
    "tags = []\n",
    "for r in etr_test[y.columns].values:\n",
    "    r = list(r)\n",
    "    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.23], reverse=True)]))\n",
    "\n",
    "test['tags'] = tags\n",
    "test[['image_name','tags']].to_csv('submission_blend.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "584ecb7e-d4fb-e8e4-0707-a1abef34e0f8"
   },
   "source": [
    "Model 2\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dea02b47-2b9f-7004-6dd4-63349d24f246",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_train = pd.DataFrame(train[['path']], columns=['path'])\n",
    "xgb_test = pd.DataFrame(test[['image_name']], columns=['image_name'])\n",
    "print('xgb fit...')\n",
    "for c in y.columns:\n",
    "    model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=4, seed=1, base_score=0.5)\n",
    "    model.fit(np.array(xtrain), y[c])\n",
    "    xgb_train[c] = model.predict_proba(np.array(xtrain))[:, 1]\n",
    "    xgb_test[c] = model.predict_proba(np.array(xtest))[:, 1]\n",
    "    print(c)\n",
    "\n",
    "train_pred = xgb_train[y.columns].values\n",
    "train_pred[train_pred >0.20] = 1\n",
    "train_pred[train_pred < 1] = 0\n",
    "print(fbeta_score(y,train_pred,beta=2, average='samples')) \n",
    "print('xgb predict...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2361e62d-85f1-d041-e3aa-b988f69075ac",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "th = []\n",
    "train_predx = xgb_train[y.columns].values\n",
    "for i in np.arange(0.0, 0.9, 0.01):\n",
    "    train_pred = train_predx.copy()\n",
    "    train_pred[train_pred >i] = 1\n",
    "    train_pred[train_pred < 1] = 0\n",
    "    th.append([i, fbeta_score(y,train_pred,beta=2, average='samples')])\n",
    "_ = pd.DataFrame(th, columns=['th','f2_score']).plot(kind='line', x='th', y='f2_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "479d9f76-56d2-2999-e0d8-ed781c9fb9af"
   },
   "source": [
    "Blend\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0505c24-f558-62f4-37fe-31e02154877d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_test.columns = [x+'_' if x not in ['image_name'] else x for x in xgb_test.columns]\n",
    "blend = pd.merge(etr_test, xgb_test, how='left', on='image_name')\n",
    "\n",
    "for c in y.columns:\n",
    "    blend[c] = (blend[c] * 0.60)  + (blend[c+'_'] * 0.40)\n",
    "\n",
    "blend = blend[etr_test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c48167f2-ae05-dfcb-3b9b-95927dc4121c"
   },
   "source": [
    "Prepare Submission\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b965d747-ed78-0741-f899-c5b875b7d3e5",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = []\n",
    "for r in blend[y.columns].values:\n",
    "    r = list(r)\n",
    "    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.20], reverse=True)]))\n",
    "\n",
    "test['tags'] = tags\n",
    "test[['image_name','tags']].to_csv('submission_blend.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a57263d0-0734-cbc6-ddac-cbe224e5e859"
   },
   "source": [
    "Visualize Results\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5012d37-5260-8d83-ef71-0fe916c9953e",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in y.columns:\n",
    "    try:\n",
    "        pathsx = test[test['tags'].str.contains(str(l))==True].path.tolist()[:9]\n",
    "        plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(l)\n",
    "        for x in range(9):\n",
    "                plt.subplot(3, 3, x+1)\n",
    "                im = Image.open(pathsx[x])\n",
    "                #im = im.resize((100, 100), Image.ANTIALIAS)\n",
    "                plt.imshow(im)\n",
    "                plt.axis('off')\n",
    "    except:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28d87f52-af77-13bc-8886-7814b0f0ed0a"
   },
   "source": [
    "Visualize Feature Importance\n",
    "============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "380fd559-c85b-f961-97dd-c04e0b55d240",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = ['sum1','sum2','sum3','sum4','mean1','mean2','mean3','mean4','rms1','rms2','rms3','rms4','var1','var2','var3','var4','stddev1','stddev2','stddev3','stddev4','kurtosis1','kurtosis2','kurtosis3','skew1','skew2','skew3']\n",
    "col += ['bw'+str(i) for i in range(256)]\n",
    "col += ['r'+str(i) for i in range(256)]\n",
    "col += ['g'+str(i) for i in range(256)]\n",
    "col += ['b'+str(i) for i in range(256)]\n",
    "col += ['infrared'+str(i) for i in range(256)]\n",
    "col += ['nvdi'+str(i) for i in range(60)]\n",
    "col += ['cv2mean1','cv2mean2','cv2mean3','cv2stddev1','cv2stddev2','cv2stddev3','Laplacian_bw','Laplacian_img','Sobel1_bw','Sobel2_bw','Sobel1_img','Sobel2_img','black_bw','white_bw']\n",
    "imp = etr.feature_importances_\n",
    "feat_imp = [[imp[i], col[i]] for i in range(len(imp))]\n",
    "_ = pd.DataFrame(feat_imp, columns=['importance','column']).sort_values(['importance','column'], ascending=[False, False])[:30].plot(kind='barh', x='column', y='importance')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 108,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
